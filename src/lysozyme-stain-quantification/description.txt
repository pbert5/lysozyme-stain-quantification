werre going to rebuild my pipeline from scratch in the new src, the old content is in src_outdated

here is how its going to work, 
our core will be run.py, this will handel taking in all of the nessesary parameter to run the whole script, it will recieve: img_dir( assume images aslo in subdirs and are only tiffs), and results_dir, along with a string to identify the red channel, and a string to identify the blue channel, and a dict of string keys to pixel dimensions in um (for now it will be defualt(aka if no other strings match):0.4476  , "40x-4":0.2253)
, it will then be responsible for first checking if they all exist, then going into the image dir and finding the red and blue channel paird tiff files, it will then pass the loaded images over to a bulk proccessor, which will then send each pair over to a individual  proc class which will then run them on to a extractor pipeline class using this style of operation but in singular: 
# Cell 2: Watershed refinement using expanded labels over RFP/DAPI pairs
import numpy as np
from skimage.segmentation import expand_labels, watershed, find_boundaries
from scipy.ndimage import label as ndi_label, distance_transform_edt
import tifffile, cv2
from pathlib import Path
from skimage import morphology

# Reuse existing 'pairs' if created earlier; otherwise build it quickly.
if 'pairs' not in globals():
    images_root = project_root / 'lysozyme images'
    red_files = sorted(list(images_root.rglob('*_RFP.tif')) + list(images_root.rglob('*_RFP.tiff')))
    def _match_blue(r_path: Path):
        stem = r_path.name
        if '_RFP.' not in stem:
            return None
        base = stem.split('_RFP.')[0]
        for ext in ['tif','tiff','TIF','TIFF']:
            cand = r_path.with_name(f'{base}_DAPI.{ext}')
            if cand.exists():
                return cand
        return None
    pairs = []
    for _r in red_files:
        b = _match_blue(_r)
        if b is not None:
            pairs.append((_r,b))
        if len(pairs) >= 30:
            break
    if not pairs:
        print('No RFP/DAPI pairs found. Aborting watershed cell.')

# Helper loaders (reuse if already defined).
if 'load_as_gray' not in globals():
    def load_as_gray(p: Path):
        arr = tifffile.imread(p)
        if arr.ndim == 3:
            if arr.shape[0] <= 4 and arr.shape[0] < arr.shape[-1]:
                arr = np.moveaxis(arr, 0, -1)
            if arr.shape[-1] in (3,4):
                arr = cv2.cvtColor(arr[..., :3].astype(np.uint8), cv2.COLOR_RGB2GRAY)
            else:
                arr = arr[...,0]
        return arr.astype(np.float32)
if 'build_rgb' not in globals():
    def build_rgb(red_gray, blue_gray):
        def to_u8(x):
            if x.dtype != np.uint8:
                lo, hi = np.nanmin(x), np.nanmax(x)
                if hi > lo:
                    x = (x - lo)/(hi-lo)*255.0
                else:
                    x = np.zeros_like(x)
                return x.astype(np.uint8)
            return x
        r8 = to_u8(red_gray)
        b8 = to_u8(blue_gray)
        zeros = np.zeros_like(r8)
        return np.stack([r8, zeros, b8], axis=-1)

# Provided helper: minmax01
def minmax01(x, eps=1e-12):
    x = x.astype(float, copy=False)
    lo = np.min(x)
    hi = np.max(x)
    return (x - lo) / max(hi - lo, eps)

max_show = 30  # limit visualization
for idx, (r_fp, b_fp) in enumerate(pairs[:max_show], 1):
    try:
        r = load_as_gray(r_fp)
        b = load_as_gray(b_fp)
    except Exception as e:
        print(f'[skip] read error {r_fp.name}/{b_fp.name}: {e}')
        continue
    if r.shape != b.shape:
        print(f'[skip] shape mismatch {r.shape} vs {b.shape}: {r_fp.name}')
        continue
    disp = build_rgb(r, b)
    try:
        disp = remove_rectangles(disp)
    except Exception:
        pass

    # Red / Blue channels for logic
    red = disp[...,0].astype(np.float32)
    blue = disp[...,2].astype(np.float32)

    # Simple morphological reconstruction style differences (reuse earlier approach)
    mask_r_dilation = np.maximum(blue, red)
    mask_r_erosion  = np.minimum(blue, red)
    # Keep lightweight (no explicit recon here if not imported); fall back to raw comparisons:
    # diff_r: red stronger than min envelope (using simple comparison as placeholder for recon_e).
    diff_r = red > mask_r_erosion
    diff_r = morphology.binary_erosion(diff_r, footprint=np.ones((3,3)))
    diff_r = morphology.remove_small_objects(diff_r, min_size=100)

    # Secondary mask (analogous to mask_gt_red) using absolute difference with 'dilation' surrogate
    abs_diff = np.abs(mask_r_dilation - red)
    mask_gt_red = abs_diff > red
    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6,6))
    mask_u8 = (mask_gt_red.astype(np.uint8)*255)
    mask_eroded_u8 = cv2.erode(mask_u8, erosion_kernel, iterations=2)
    mask_gt_red_eroded = mask_eroded_u8.astype(bool)

    # Build combined_labels (0 bg, 1 diff_r, 2 mask_gt_red)
    combined_labels = np.zeros_like(diff_r, dtype=int)
    combined_labels[mask_gt_red_eroded] = 2
    combined_labels[diff_r] = 1

    # Expand labels
    expanded_labels = expand_labels(combined_labels, distance=100)

    # Markers from diff_r
    labeled_diff_r, _ = ndi_label(diff_r != 0)

    # Reworked markers array
    reworked = np.zeros_like(expanded_labels, dtype=np.int32)
    reworked[expanded_labels == 2] = 1  # entire class 2 region => marker 1
    mask_copy = (expanded_labels != 2) & (labeled_diff_r != 0)
    reworked[mask_copy] = labeled_diff_r[mask_copy] + 1

    # Watershed mask
    mask_ws = expanded_labels > 0

    # Elevation: attract to class 2, repel from class 1
    elevation = (
        minmax01(distance_transform_edt(combined_labels == 2))
        - minmax01(distance_transform_edt(combined_labels == 1))
    )

    ws_labels = watershed(elevation, markers=reworked, mask=mask_ws)

    # Visual overlay
    boundaries = find_boundaries(ws_labels, mode='inner')
    overlay_ws = disp.copy()
    overlay_ws[boundaries] = [255, 0, 0]


the  extractor pipeline will pass back a labeld np array of the blobs, the  individual  proc class  will then run the labels through a merger pipeline following this logic:
class MergePipeline:
        def __init__(self, label_img, raw_img=None, singleton_penalty=10.0, sample_size=100):
            self.label_img = label_img
            self.raw_img = raw_img
            self.singleton_penalty = singleton_penalty
            self.sample_size = sample_size
            
            # Will be populated
            self.props = {}
            self.perims = {}
            self.cents = {}
            self.areas = {}
            self.shared = defaultdict(lambda: defaultdict(int))
            self.triangles = []
            self.combos = {}
            self.best_stage1 = {}
            self.second_stage_results = {}
            self.merged_label_array = None

        def compute_stats(self):
            # Compute region properties
            self.props = {r.label: r for r in regionprops(self.label_img)}
            self.perims = {lbl: perimeter(self.label_img == lbl) for lbl in self.props}
            self.cents = {lbl: self.props[lbl].centroid for lbl in self.props}
            self.areas = {lbl: self.props[lbl].area for lbl in self.props}
            # Build shared-perimeter adjacency
            for lbl in self.props:
                mask = self.label_img == lbl
                dil = dilation(mask, np.ones((3,3), dtype=bool))
                neighs = set(np.unique(self.label_img[dil])) - {0, lbl}
                for n in neighs:
                    shared_p = int(np.logical_and(dil, self.label_img==n).sum())
                    self.shared[lbl][n] = shared_p
                    self.shared[n][lbl] = shared_p
            return self

        def find_triangles(self):
            triangles = set()
            for a in self.shared:
                neighs = list(self.shared[a])
                for b, c in combinations(neighs, 2):
                    if b in self.shared[c] and c in self.shared[b]:
                        triangles.add(tuple(sorted((a, b, c))))
            self.triangles = sorted(triangles)
            return self

        def build_candidate_groups(self):
            tri_index = defaultdict(list)
            for tri in self.triangles:
                for lbl in tri:
                    tri_index[lbl].append(tri)
            combos = defaultdict(list)
            for lbl in self.shared:
                combos[lbl].append((lbl,))
                for n in self.shared[lbl]:
                    if n != lbl:
                        combos[lbl].append((lbl, n))
                combos[lbl].extend(tri_index[lbl])
                seen = set()
                for t1 in tri_index[lbl]:
                    for t2 in tri_index[lbl]:
                        if t1 == t2:
                            continue
                        inter = set(t1).intersection(t2)
                        if len(inter) == 2 and lbl in inter:
                            merged = tuple(sorted(set(t1).union(t2)))
                            if merged not in seen:
                                combos[lbl].append(merged)
                                seen.add(merged)
            self.combos = combos
            return self

        def evaluate_stage1(self):
            best = {}
            for lbl, clist in self.combos.items():
                P = self.perims[lbl]
                best_score, best_combo = -1.0, (lbl,)
                for combo in clist:
                    if combo == (lbl,):
                        score = 1.0 / self.singleton_penalty
                    else:
                        shared_sum = sum(self.shared[lbl][n] for n in combo if n != lbl)
                        score = shared_sum / (P + 1e-8)
                    if score > best_score:
                        best_score, best_combo = score, combo
                best[lbl] = (best_combo, best_score)
                    # ←–– New block to catch “no-combo” labels ––→
            for lbl in self.props:
                if lbl not in best:
                    best[lbl] = ((lbl,), 1.0/self.singleton_penalty)
                    
            self.best_stage1 = best
            return self

        def evaluate_stage2(self):
            # assign groups and leaders
            group_map = defaultdict(set)
            for lbl, (group, _) in self.best_stage1.items():
                norm = tuple(sorted(int(g) for g in group))
                group_map[norm].add(int(lbl))
            group_leaders = {grp: max(grp, key=lambda x: self.areas[x]) for grp in group_map}
            # stage2 results
            results = {}
            for grp, members in group_map.items():
                leader = group_leaders[grp]
                expanded = set(grp)
                for l in grp:
                    expanded.update(self.shared[l].keys())
                expanded = {int(l) for l in expanded if int(l) in self.props}
                for lbl in members:
                    # compute score
                    tot_area = sum(self.areas[l] for l in expanded)
                    tot_perim = sum(self.perims[l] for l in expanded)
                    coords = np.vstack([self.props[l].coords for l in expanded])
                    com = coords.mean(axis=0)
                    lbl_coords = self.props[lbl].coords
                    if len(lbl_coords) > self.sample_size:
                        idx = np.linspace(0, len(lbl_coords)-1, self.sample_size).astype(int)
                        lbl_coords = lbl_coords[idx]
                    dists = np.linalg.norm(lbl_coords - com, axis=1)
                    avg_dist = dists.mean()
                    score2 = (tot_area / (tot_perim + 1e-8)) / (avg_dist + 1e-8)
                    results[lbl] = (leader, score2)
            # add true singletons
            all_lbls = set(self.props.keys())
            for lbl in all_lbls - set(results):
                results[int(lbl)] = (int(lbl), 0.0)
            self.second_stage_results = results
            return self

        def relabel(self):
            mapping = {lbl: tgt for lbl, (tgt, _) in self.second_stage_results.items()}
            out = np.zeros_like(self.label_img)
            for old, new in mapping.items():
                out[self.label_img == old] = new
            self.merged_label_array = out
            return self

        def run(self):
            return (self.compute_stats()
                        .find_triangles()
                        .build_candidate_groups()
                        .evaluate_stage1()
                        .evaluate_stage2()
                        .relabel())

        def plot_initial(self, title="Original Labels"):
            img = label2rgb(self.label_img, bg_label=0)
            plt.figure(figsize=(6,6))
            plt.imshow(img); plt.title(title); plt.axis('off')

        def plot_stage1(self, title="Stage 1 Groupings"):
            img = label2rgb(self.label_img, bg_label=0)
            plt.figure(figsize=(6,6))
            plt.imshow(img); plt.title(title); plt.axis('off')
            for region in regionprops(self.label_img):
                if region.label == 0: continue
                grp, _ = self.best_stage1[region.label]
                txt = ",".join(str(int(x)) for x in grp)
                y,x = region.centroid
                plt.text(x,y,txt,ha='center',va='center',color='white',
                        bbox=dict(facecolor='black',alpha=0.5,lw=0))

        def plot_final(self, title="Final Merged Labels"):
            img = label2rgb(self.merged_label_array, bg_label=0)
            plt.figure(figsize=(6,6))
            plt.imshow(img); plt.title(title); plt.axis('off')
            for region in regionprops(self.merged_label_array):
                if region.label == 0: continue
                y,x = region.centroid
                plt.text(x,y,str(region.label),ha='center',va='center',color='white',
                        bbox=dict(facecolor='black',alpha=0.5,lw=0))


so now the individual  proc class will have both the original detected labels and then the merged labels, its default run method will pass back the final merged labels (but it like all other classes in our system will have a debug method which will return a dict of renderings in this case it will be the combinded rgb with the labeld regions thick outlines overlayed on top) along with a label summary np array using the pixel dimensions ( which will also need to be passed down) it will have id, position, area, sum of red value pixels, sum of red value pixels divided by area.

the bulk proccessor will collect all of these, save the debug visualizations to matching subdirs of the of the output dir, and a consolidated quick_check that has the merged labels outlines overlayed over the combined rb

make sure this all #codebase works, and use my preexisitng C:\Users\admin\Documents\Pierre lab\projects\Colustrum-ABX\lysozyme stain quantification\.venv, also come up with a logical project subdir strucutre to put all the new scripts in

and make sure to add tests to C:\Users\admin\Documents\Pierre lab\projects\Colustrum-ABX\lysozyme stain quantification\code\tests and just add src back to the py path in the script so it can access
