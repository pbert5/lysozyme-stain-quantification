i want to make an R script in C:\Users\admin\Documents\Pierre lab\projects\Colustrum-ABX\lysozyme stain quantification\code\src\proc.r

that processes C:\Users\admin\Documents\Pierre lab\projects\Colustrum-ABX\lysozyme stain quantification\results\All\summaries\consolidated_summary.csv
tho first were going to need to make some edits of the #codebase to make it compatible, 
first we need it to account for images that come from a subdir contianing "Jej LYZ" are seperate from the rest and should be treated like how we are treating retakes in terms of name based seperation

then i want to replace 
the red_intensity value with flourescense = red_sum_pixels/area_pixels*area_um2,
then to enable noramlization, we will also need to get out whole image parameters such as background_tisue_intesisty = average per_pixel_ratio of red to blue channel in region 1 of the ws_labels before it gets removed in C:\Users\admin\Documents\Pierre lab\projects\Colustrum-ABX\lysozyme stain quantification\code\src\processing\extractor_pipeline.py ( since that should be the background tissue) and then average_cypt_intensity = average per_pixel_ratio of red to blue channel in the rest of the ws_labels excluding 0
the ratio between average_cypt_intensityand background_tisue_intesisty should represent the per image contrast of background tissue to crypts, which should allow us to normalize flourescence values between images
aka were going to use it to normalize flourescense across crypts between images


its going to recerate how the follwoing works: # first step import the data
```{r}
library(dplyr)
library(tidyr)
library(readr)

dfOG = read_csv("./input_data/2025-07-09_measurments_corrected.csv", show_col_types = FALSE) |> mutate(source = "OG")

dfRetakes = read_csv("./input_data/Retakes2-2025-07-24_measurments.csv", show_col_types = FALSE) |> mutate(source = "Retakes")
```


```{r}
# check for duplicates in the images across the sets
dup_images = intersect(dfOG$Image, dfRetakes$Image)

# Remove duplicates from dfOG
dfOG_nodup = dfOG |> filter(!(Image %in% dfRetakes$Image))



df = bind_rows(dfOG, dfRetakes) |>  select(where(~!all(is.na(.)))) |> mutate(fluorescence = `Area µm^2`*`ROI: 2.00 µm per pixel: Red: Mean`)






```

```{r}
library(stringr)
summary = df |> mutate(Has40x=str_detect(Image, "40x"))
summary
```

# illustrate funciton
```{r}
# install.packages(c("ggplot2","readr"))  # if not already installed

library(readr)
library(ggplot2)
library(RColorBrewer)

# This function plots mean and SD values for a given dataset, with optional grouping and count annotation.
plot_mean_sd <- function(data, x_col="Animal", mean_col="mean_fluorescence",
                         sd_col="sd_fluorescence", group_col=NULL,  count_col  = NULL,
                         palette="Set2", x_label=NULL, y_label=NULL,
                         plot_title=NULL) {
  
  aes_map <- if (is.null(group_col)) { # set up ggplot mapping, optionally with grouping
    aes_string(x=x_col, y=mean_col)
  } else {
    aes_string(x=x_col, y=mean_col, fill=group_col)
  }

  p <- ggplot(data, aes_map) + # create base plot
    geom_col() + # bar plot for means
    geom_errorbar(aes_string(
      ymin = paste0(mean_col, " - ", sd_col),
      ymax = paste0(mean_col, " + ", sd_col)
    ), width = 0.2) + # error bars for SD
    labs(x=x_label, y=y_label, title=plot_title) # axis labels and title
  
  if (!is.null(count_col)) { # add count annotation if provided
    p <- p + geom_text(aes_string(label = count_col),
                       y    = 0,
                       vjust = 1.5,
                       size  = 3)
  }

  if (!is.null(group_col)) { # set up color palette for groups
    n <- length(unique(data[[group_col]])) # number of groups
    max_b <- brewer.pal.info[palette, "maxcolors"] # max palette colors
    base_cols <- brewer.pal(min(n, max_b), palette) # base colors
    cols <- if (n <= max_b) base_cols else colorRampPalette(base_cols)(n) # interpolate if needed
    p <- p + scale_fill_manual(values=cols, name=group_col)
  } else {
    p <- p + scale_fill_manual(values="steelblue", guide="none") # single color if no grouping
  }

  p + theme_bw() + # clean theme
    theme(axis.text.x = element_text(angle=45, hjust=1), # rotate x labels
          panel.grid.major.x = element_blank()) # remove vertical grid lines
}
```



# plan
in order to account for the large variability between images of the same animal, I will produce two csvs, one where all images from a single animal are collapsed together by averging, and another where for each animal a single best image is chosen
## common variables
```{r}
sd_ratio_limit = 0.5 # this is the limit for the sd ratio, images with a higher sd ratio will be filtered out
```


## first preperation

```{r}
# first group by image
by_image = df |> group_by(Image) |> slice_max(
  order_by = fluorescence, n = 5 # this takes the 5 best rois per image
  ) |> summarise(
  mean_fluorescence = mean(fluorescence, na.rm = TRUE),
  sd_fluorescence = sd(fluorescence, na.rm = TRUE),
  sd_ratio = sd_fluorescence / mean_fluorescence, #this is a measure of how variable the fluorescence is within an image for refference
  .groups = "drop"
)|> mutate(Animal = substr(Image, 1, 4)) #grab the first four characters of the image name which should be the animal ID

original_animal_list = by_image |> pull(Animal) |> unique() #literaly build the unique lsit of animal ids present

# then filter out images with too high sd



# then plot before sd filtering
by_image = by_image |> filter(sd_ratio < sd_ratio_limit) ## filter out images of too high sd
plot_mean_sd(by_image, 
             x_col = "Image", 
             mean_col = "mean_fluorescence", 
             sd_col = "sd_fluorescence",
             group_col = "Animal",
             x_label = "Image",
             y_label = "Mean Fluorescence (± SD)",
             plot_title = "Mean Fluorescence by Image with SD Whiskers")

```
## alt: grab best image by animal
criteria = fluorescence value
```{r}
best_image_per_animal = by_image |> 
  group_by(Animal) |> 
  slice_max(order_by = mean_fluorescence, n = 1) |> 
  ungroup() |> 
  select(Image, Animal, mean_fluorescence, sd_fluorescence, sd_ratio)
# then plot
plot_mean_sd(best_image_per_animal, 
             x_col = "Animal", 
             mean_col = "mean_fluorescence", 
             sd_col = "sd_fluorescence",
             group_col = "Animal",
             x_label = "Animal",
             y_label = "Mean Fluorescence (± SD)",
             plot_title = "Best individual Image Fluorescence by Animal")

```

## alt: then collapse the data by animal
```{r}
# then group by animal
by_animal_average = df |> group_by(Image) |> slice_max(order_by = fluorescence, n = 5) |> # this takes the 5 best rois per image
  ungroup() |>
  mutate(Animal = substr(Image, 1, 4)) |> #grab the first four characters of the image name which should be the animal ID
  group_by(Animal) |> 
  summarise(
    mean_fluorescence_per_animal = mean(fluorescence, na.rm = TRUE),
    sd_fluorescence = sd(fluorescence, na.rm = TRUE),
    CV = sd_fluorescence / mean_fluorescence_per_animal, # this is a measure of how variable the fluorescence is within an animal
    n_images = length(unique(Image)), # this counts the number of unique images per animal
    .groups = "drop"
  )
#animals_below_sd= by_animal |> pull(Animal)
# then plot
plot_mean_sd(by_animal_average, 
             x_col = "Animal", 
             mean_col = "mean_fluorescence_per_animal", 
             sd_col = "sd_fluorescence",
             group_col = "Animal",
             count_col = "n_images",
             x_label = "Animal",
             y_label = "Mean Fluorescence (± SD)",
             plot_title = "Mean Fluorescence by Animal with SD Whiskers")

```
# then save the data
```{r}
# Make sure output folder exists
if (!dir.exists("output_data")) dir.create("output_data")

write_csv(df, "output_data/all_data.csv")
write_csv(by_image, "output_data/by_image.csv")
write_csv(by_animal_average, "output_data/by_animal_average.csv")
write_csv(best_image_per_animal, "output_data/best_image_per_animal.csv")
```
```
# then save the data

```{r}

write_csv(by_image, "input_data/by_image.csv")
write_csv(by_animal_average, "by_animal_average.csv")
write_csv(best_image_per_animal, "best_image_per_animal.csv")
```
flourescense will instead just be 






execpt with some modified behavior,
1. we need it to account for results/All/summaries/visual_inspection_ratings.csv and only take the good images
first all are results are already consolidated, then we going to want to create grouping tags column for if they are normal, vrs retakes, vrs jej. this is going to come up for by animal where we will want to make two outputs, one where they collapse all from the same animal together, and another where they seperate based on tags

should also include meta list about which animals are missing what, how many images were used per