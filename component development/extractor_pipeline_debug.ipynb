{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e9032a",
   "metadata": {},
   "source": [
    "# Extractor Pipeline Debug Notebook\n",
    "\n",
    "This notebook compares the original working watershed algorithm with the new ExtractorPipeline implementation to identify and fix differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Data Loading\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.stats import entropy as scipy_entropy\n",
    "from scipy.ndimage import binary_fill_holes, label as ndi_label, distance_transform_edt\n",
    "from skimage.segmentation import expand_labels, watershed, find_boundaries\n",
    "from skimage import morphology\n",
    "import sys\n",
    "\n",
    "# Project paths\n",
    "notebook = Path(r\"C:\\Users\\admin\\Documents\\Pierre lab\\projects\\Colustrum-ABX\\lysozyme stain quantification\\code\\component development\")\n",
    "project_root = notebook.parent.parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add src to path to import our pipeline\n",
    "src_path = project_root / \"code\" / \"src\"\n",
    "sys.path.insert(0, str(src_path))\n",
    "print(f\"Added to path: {src_path}\")\n",
    "\n",
    "# Test that we can import our pipeline\n",
    "try:\n",
    "    from processing.extractor_pipeline import ExtractorPipeline\n",
    "    from utils.file_utils import load_as_gray, build_rgb, remove_rectangles\n",
    "    from utils.image_utils import minmax01\n",
    "    print(\"âœ“ Successfully imported pipeline components\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Import failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image and prepare helper functions\n",
    "images_root = project_root / 'lysozyme images'\n",
    "test_red_path = images_root / \"Jej LYZ\" / \"G2\" / \"G2EL - 1_RFP.tif\"\n",
    "test_blue_path = images_root / \"Jej LYZ\" / \"G2\" / \"G2EL - 1_DAPI.tif\"\n",
    "\n",
    "print(f\"Red path exists: {test_red_path.exists()}\")\n",
    "print(f\"Blue path exists: {test_blue_path.exists()}\")\n",
    "\n",
    "# Original notebook helper functions\n",
    "def load_as_gray_orig(p: Path):\n",
    "    \"\"\"Original notebook version\"\"\"\n",
    "    arr = tifffile.imread(p)\n",
    "    if arr.ndim == 3:\n",
    "        if arr.shape[0] <= 4 and arr.shape[0] < arr.shape[-1]:\n",
    "            arr = np.moveaxis(arr, 0, -1)\n",
    "        if arr.shape[-1] in (3,4):\n",
    "            arr = cv2.cvtColor(arr[..., :3].astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            arr = arr[...,0]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def build_rgb_orig(red_gray, blue_gray):\n",
    "    \"\"\"Original notebook version\"\"\"\n",
    "    def to_u8(x):\n",
    "        if x.dtype != np.uint8:\n",
    "            lo, hi = np.nanmin(x), np.nanmax(x)\n",
    "            if hi > lo:\n",
    "                x = (x - lo)/(hi-lo)*255.0\n",
    "            else:\n",
    "                x = np.zeros_like(x)\n",
    "            return x.astype(np.uint8)\n",
    "        return x\n",
    "    r8 = to_u8(red_gray)\n",
    "    b8 = to_u8(blue_gray)\n",
    "    zeros = np.zeros_like(r8)\n",
    "    return np.stack([r8, zeros, b8], axis=-1)\n",
    "\n",
    "def minmax01_orig(x, eps=1e-12):\n",
    "    \"\"\"Original notebook version\"\"\"\n",
    "    x = x.astype(float, copy=False)\n",
    "    lo = np.min(x)\n",
    "    hi = np.max(x)\n",
    "    return (x - lo) / max(hi - lo, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ddaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images - Compare methods\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARING IMAGE LOADING AND PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load with original method\n",
    "r_orig = load_as_gray_orig(test_red_path)\n",
    "b_orig = load_as_gray_orig(test_blue_path)\n",
    "print(f\"Original method - Red: {r_orig.shape}, range [{r_orig.min():.2f}, {r_orig.max():.2f}]\")\n",
    "print(f\"Original method - Blue: {b_orig.shape}, range [{b_orig.min():.2f}, {b_orig.max():.2f}]\")\n",
    "\n",
    "# Load with pipeline method\n",
    "r_pipeline = load_as_gray(test_red_path)\n",
    "b_pipeline = load_as_gray(test_blue_path)\n",
    "print(f\"Pipeline method - Red: {r_pipeline.shape}, range [{r_pipeline.min():.2f}, {r_pipeline.max():.2f}]\")\n",
    "print(f\"Pipeline method - Blue: {b_pipeline.shape}, range [{b_pipeline.min():.2f}, {b_pipeline.max():.2f}]\")\n",
    "\n",
    "# Check if they're identical\n",
    "print(f\"Red images identical: {np.allclose(r_orig, r_pipeline)}\")\n",
    "print(f\"Blue images identical: {np.allclose(b_orig, b_pipeline)}\")\n",
    "\n",
    "# Build RGB with both methods\n",
    "disp_orig = build_rgb_orig(r_orig, b_orig)\n",
    "disp_pipeline = build_rgb(r_pipeline, b_pipeline)\n",
    "\n",
    "print(f\"Original RGB: {disp_orig.shape}, dtype {disp_orig.dtype}\")\n",
    "print(f\"Pipeline RGB: {disp_pipeline.shape}, dtype {disp_pipeline.dtype}\")\n",
    "print(f\"RGB displays identical: {np.allclose(disp_orig, disp_pipeline)}\")\n",
    "\n",
    "# Use original method for the rest (to match notebook exactly)\n",
    "r = r_orig\n",
    "b = b_orig\n",
    "disp = disp_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca928ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL NOTEBOOK ALGORITHM (STEP BY STEP)\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING ORIGINAL NOTEBOOK ALGORITHM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Apply remove_rectangles\n",
    "try:\n",
    "    disp = remove_rectangles(disp)\n",
    "    print(\"âœ“ Rectangle removal applied\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Rectangle removal failed: {e}\")\n",
    "\n",
    "# Extract red and blue channels from display\n",
    "red_orig = disp[...,0].astype(np.float32)\n",
    "blue_orig = disp[...,2].astype(np.float32)\n",
    "print(f\"Red from display: range [{red_orig.min():.2f}, {red_orig.max():.2f}]\")\n",
    "print(f\"Blue from display: range [{blue_orig.min():.2f}, {blue_orig.max():.2f}]\")\n",
    "\n",
    "# Morphological operations\n",
    "mask_r_dilation_orig = np.maximum(blue_orig, red_orig)\n",
    "mask_r_erosion_orig = np.minimum(blue_orig, red_orig)\n",
    "print(f\"Dilation mask: range [{mask_r_dilation_orig.min():.2f}, {mask_r_dilation_orig.max():.2f}]\")\n",
    "print(f\"Erosion mask: range [{mask_r_erosion_orig.min():.2f}, {mask_r_erosion_orig.max():.2f}]\")\n",
    "\n",
    "# diff_r\n",
    "diff_r_orig = red_orig > mask_r_erosion_orig\n",
    "print(f\"diff_r raw: {np.sum(diff_r_orig)} pixels\")\n",
    "\n",
    "diff_r_orig = morphology.binary_erosion(diff_r_orig, footprint=np.ones((3,3)))\n",
    "diff_r_orig = morphology.remove_small_objects(diff_r_orig, min_size=100)\n",
    "print(f\"diff_r final: {np.sum(diff_r_orig)} pixels\")\n",
    "\n",
    "# Secondary mask\n",
    "abs_diff_orig = np.abs(mask_r_dilation_orig - red_orig)\n",
    "mask_gt_red_orig = abs_diff_orig > red_orig\n",
    "print(f\"abs_diff range: [{abs_diff_orig.min():.2f}, {abs_diff_orig.max():.2f}]\")\n",
    "print(f\"mask_gt_red: {np.sum(mask_gt_red_orig)} pixels\")\n",
    "\n",
    "# Erosion\n",
    "erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6,6))\n",
    "mask_u8 = (mask_gt_red_orig.astype(np.uint8)*255)\n",
    "mask_eroded_u8 = cv2.erode(mask_u8, erosion_kernel, iterations=2)\n",
    "mask_gt_red_eroded_orig = mask_eroded_u8.astype(bool)\n",
    "print(f\"mask_gt_red_eroded: {np.sum(mask_gt_red_eroded_orig)} pixels\")\n",
    "\n",
    "# Combined labels\n",
    "combined_labels_orig = np.zeros_like(diff_r_orig, dtype=int)\n",
    "combined_labels_orig[mask_gt_red_eroded_orig] = 2\n",
    "combined_labels_orig[diff_r_orig] = 1\n",
    "unique_combined = np.unique(combined_labels_orig)\n",
    "counts = [(label, np.sum(combined_labels_orig == label)) for label in unique_combined]\n",
    "print(f\"Combined labels: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete original watershed algorithm\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLETING ORIGINAL WATERSHED ALGORITHM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Expand labels\n",
    "expanded_labels_orig = expand_labels(combined_labels_orig, distance=100)\n",
    "unique_expanded = np.unique(expanded_labels_orig)\n",
    "print(f\"Expanded labels: {len(unique_expanded)} unique values\")\n",
    "if len(unique_expanded) <= 20:\n",
    "    print(f\"Expanded values: {unique_expanded}\")\n",
    "\n",
    "# Markers from diff_r\n",
    "labeled_diff_r_orig, _ = ndi_label(diff_r_orig != 0)\n",
    "print(f\"labeled_diff_r: max {labeled_diff_r_orig.max()} regions\")\n",
    "\n",
    "# Reworked markers\n",
    "reworked_orig = np.zeros_like(expanded_labels_orig, dtype=np.int32)\n",
    "reworked_orig[expanded_labels_orig == 2] = 1\n",
    "mask_copy = (expanded_labels_orig != 2) & (labeled_diff_r_orig != 0)\n",
    "reworked_orig[mask_copy] = labeled_diff_r_orig[mask_copy] + 1\n",
    "unique_reworked = np.unique(reworked_orig)\n",
    "print(f\"Reworked markers: {len(unique_reworked)} unique, max: {reworked_orig.max()}\")\n",
    "\n",
    "# Watershed mask\n",
    "mask_ws_orig = expanded_labels_orig > 0\n",
    "print(f\"Watershed mask: {np.sum(mask_ws_orig)} pixels\")\n",
    "\n",
    "# Elevation\n",
    "elevation_orig = (\n",
    "    minmax01_orig(distance_transform_edt(combined_labels_orig == 2))\n",
    "    - minmax01_orig(distance_transform_edt(combined_labels_orig == 1))\n",
    ")\n",
    "print(f\"Elevation range: [{elevation_orig.min():.3f}, {elevation_orig.max():.3f}]\")\n",
    "\n",
    "# Final watershed\n",
    "ws_labels_orig = watershed(elevation_orig, markers=reworked_orig, mask=mask_ws_orig)\n",
    "unique_ws = np.unique(ws_labels_orig)\n",
    "print(f\"Final watershed: {len(unique_ws)} regions, max label: {ws_labels_orig.max()}\")\n",
    "if len(unique_ws) <= 20:\n",
    "    print(f\"Final labels: {unique_ws}\")\n",
    "\n",
    "# Store original results\n",
    "orig_results = {\n",
    "    'ws_labels': ws_labels_orig,\n",
    "    'expanded_labels': expanded_labels_orig,\n",
    "    'combined_labels': combined_labels_orig,\n",
    "    'diff_r': diff_r_orig,\n",
    "    'mask_gt_red_eroded': mask_gt_red_eroded_orig,\n",
    "    'disp': disp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97871328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN NEW PIPELINE AND COMPARE\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING NEW EXTRACTOR PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize pipeline with debug\n",
    "extractor = ExtractorPipeline(debug=True)\n",
    "\n",
    "# Run pipeline (using original loaded images)\n",
    "ws_labels_pipeline = extractor.extract(r, b)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare final results\n",
    "print(f\"Original final labels: {len(np.unique(orig_results['ws_labels']))} regions, max: {orig_results['ws_labels'].max()}\")\n",
    "print(f\"Pipeline final labels: {len(np.unique(ws_labels_pipeline))} regions, max: {ws_labels_pipeline.max()}\")\n",
    "print(f\"Final results identical: {np.array_equal(orig_results['ws_labels'], ws_labels_pipeline)}\")\n",
    "\n",
    "# Get debug info\n",
    "debug_info = extractor.get_debug_info()\n",
    "\n",
    "# Compare intermediate steps\n",
    "steps_to_compare = [\n",
    "    ('diff_r', 'diff_r'),\n",
    "    ('mask_gt_red_eroded', 'mask_gt_red_eroded'), \n",
    "    ('combined_labels', 'combined_labels'),\n",
    "    ('expanded_labels', 'expanded_labels'),\n",
    "    ('ws_labels', 'ws_labels')\n",
    "]\n",
    "\n",
    "for orig_key, pipeline_key in steps_to_compare:\n",
    "    if orig_key in orig_results and pipeline_key in debug_info:\n",
    "        orig_data = orig_results[orig_key]\n",
    "        pipeline_data = debug_info[pipeline_key]\n",
    "        identical = np.array_equal(orig_data, pipeline_data)\n",
    "        print(f\"{orig_key:20} identical: {identical}\")\n",
    "        if not identical:\n",
    "            print(f\"  Original unique: {np.unique(orig_data)}\")\n",
    "            print(f\"  Pipeline unique: {np.unique(pipeline_data)}\")\n",
    "            if orig_data.dtype == bool:\n",
    "                print(f\"  Original sum: {np.sum(orig_data)}\")\n",
    "                print(f\"  Pipeline sum: {np.sum(pipeline_data)}\")\n",
    "    else:\n",
    "        print(f\"{orig_key:20} - Missing data for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETAILED CHANNEL COMPARISON\n",
    "print(\"=\" * 60)\n",
    "print(\"DETAILED CHANNEL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare the critical step: channel extraction from RGB\n",
    "red_orig_extracted = red_orig  # From original: disp[...,0].astype(np.float32)\n",
    "blue_orig_extracted = blue_orig  # From original: disp[...,2].astype(np.float32)\n",
    "\n",
    "if 'red_from_disp' in debug_info and 'blue_from_disp' in debug_info:\n",
    "    red_pipeline_extracted = debug_info['red_from_disp']\n",
    "    blue_pipeline_extracted = debug_info['blue_from_disp']\n",
    "    \n",
    "    print(f\"Red channel comparison:\")\n",
    "    print(f\"  Original range: [{red_orig_extracted.min():.2f}, {red_orig_extracted.max():.2f}]\")\n",
    "    print(f\"  Pipeline range: [{red_pipeline_extracted.min():.2f}, {red_pipeline_extracted.max():.2f}]\")\n",
    "    print(f\"  Identical: {np.allclose(red_orig_extracted, red_pipeline_extracted)}\")\n",
    "    \n",
    "    print(f\"Blue channel comparison:\")\n",
    "    print(f\"  Original range: [{blue_orig_extracted.min():.2f}, {blue_orig_extracted.max():.2f}]\")\n",
    "    print(f\"  Pipeline range: [{blue_pipeline_extracted.min():.2f}, {blue_pipeline_extracted.max():.2f}]\")\n",
    "    print(f\"  Identical: {np.allclose(blue_orig_extracted, blue_pipeline_extracted)}\")\n",
    "    \n",
    "    # Check if the RGB displays are identical\n",
    "    if 'disp_rgb' in debug_info:\n",
    "        disp_pipeline = debug_info['disp_rgb']\n",
    "        print(f\"RGB display identical: {np.array_equal(disp, disp_pipeline)}\")\n",
    "        if not np.array_equal(disp, disp_pipeline):\n",
    "            print(f\"  Original RGB range: [{disp.min()}, {disp.max()}]\")\n",
    "            print(f\"  Pipeline RGB range: [{disp_pipeline.min()}, {disp_pipeline.max()}]\")\n",
    "else:\n",
    "    print(\"âš  Debug info missing channel data\")\n",
    "\n",
    "# Check morphological operations\n",
    "if 'mask_r_dilation' in debug_info and 'mask_r_erosion' in debug_info:\n",
    "    print(f\"\\nMorphological operations:\")\n",
    "    print(f\"  Dilation identical: {np.allclose(mask_r_dilation_orig, debug_info['mask_r_dilation'])}\")\n",
    "    print(f\"  Erosion identical: {np.allclose(mask_r_erosion_orig, debug_info['mask_r_erosion'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437077ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION OF RESULTS\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING COMPARISON VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create side-by-side comparison\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Row 1: Original algorithm results\n",
    "row = 0\n",
    "axes[row, 0].imshow(orig_results['diff_r'], cmap='gray')\n",
    "axes[row, 0].set_title('Original: diff_r')\n",
    "axes[row, 0].axis('off')\n",
    "\n",
    "axes[row, 1].imshow(orig_results['combined_labels'], cmap='tab10')\n",
    "axes[row, 1].set_title('Original: combined_labels')\n",
    "axes[row, 1].axis('off')\n",
    "\n",
    "axes[row, 2].imshow(orig_results['expanded_labels'], cmap='tab10')\n",
    "axes[row, 2].set_title('Original: expanded_labels')\n",
    "axes[row, 2].axis('off')\n",
    "\n",
    "axes[row, 3].imshow(orig_results['ws_labels'], cmap='tab20')\n",
    "axes[row, 3].set_title('Original: watershed')\n",
    "axes[row, 3].axis('off')\n",
    "\n",
    "# Row 2: Pipeline results\n",
    "row = 1\n",
    "if 'diff_r' in debug_info:\n",
    "    axes[row, 0].imshow(debug_info['diff_r'], cmap='gray')\n",
    "    axes[row, 0].set_title('Pipeline: diff_r')\n",
    "    axes[row, 0].axis('off')\n",
    "\n",
    "if 'combined_labels' in debug_info:\n",
    "    axes[row, 1].imshow(debug_info['combined_labels'], cmap='tab10')\n",
    "    axes[row, 1].set_title('Pipeline: combined_labels')\n",
    "    axes[row, 1].axis('off')\n",
    "\n",
    "if 'expanded_labels' in debug_info:\n",
    "    axes[row, 2].imshow(debug_info['expanded_labels'], cmap='tab10')\n",
    "    axes[row, 2].set_title('Pipeline: expanded_labels')\n",
    "    axes[row, 2].axis('off')\n",
    "\n",
    "axes[row, 3].imshow(ws_labels_pipeline, cmap='tab20')\n",
    "axes[row, 3].set_title('Pipeline: watershed')\n",
    "axes[row, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overlay comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original overlay\n",
    "boundaries_orig = find_boundaries(orig_results['ws_labels'], mode='inner')\n",
    "overlay_orig = orig_results['disp'].copy()\n",
    "overlay_orig[boundaries_orig] = [255, 0, 0]\n",
    "\n",
    "axes[0].imshow(overlay_orig)\n",
    "axes[0].set_title(f'Original Algorithm\\n{len(np.unique(orig_results[\"ws_labels\"]))} regions')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Pipeline overlay\n",
    "boundaries_pipeline = find_boundaries(ws_labels_pipeline, mode='inner')\n",
    "overlay_pipeline = orig_results['disp'].copy()\n",
    "overlay_pipeline[boundaries_pipeline] = [0, 255, 0]\n",
    "\n",
    "axes[1].imshow(overlay_pipeline)\n",
    "axes[1].set_title(f'Pipeline Algorithm\\n{len(np.unique(ws_labels_pipeline))} regions')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Combined overlay (red=original, green=pipeline)\n",
    "overlay_combined = orig_results['disp'].copy()\n",
    "overlay_combined[boundaries_orig] = [255, 0, 0]    # Red for original\n",
    "overlay_combined[boundaries_pipeline] = [0, 255, 0]  # Green for pipeline\n",
    "\n",
    "axes[2].imshow(overlay_combined)\n",
    "axes[2].set_title('Combined Overlay\\nRed=Original, Green=Pipeline')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC ANALYSIS\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSTIC ANALYSIS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze where the differences occur\n",
    "if not np.array_equal(orig_results['ws_labels'], ws_labels_pipeline):\n",
    "    print(\"âŒ ALGORITHMS PRODUCE DIFFERENT RESULTS\")\n",
    "    \n",
    "    # Find first point of divergence\n",
    "    divergence_found = False\n",
    "    \n",
    "    # Check each step\n",
    "    check_steps = [\n",
    "        ('red channels', red_orig_extracted, debug_info.get('red_from_disp')),\n",
    "        ('blue channels', blue_orig_extracted, debug_info.get('blue_from_disp')),\n",
    "        ('diff_r', orig_results['diff_r'], debug_info.get('diff_r')),\n",
    "        ('mask_gt_red_eroded', orig_results['mask_gt_red_eroded'], debug_info.get('mask_gt_red_eroded')),\n",
    "        ('combined_labels', orig_results['combined_labels'], debug_info.get('combined_labels')),\n",
    "        ('expanded_labels', orig_results['expanded_labels'], debug_info.get('expanded_labels')),\n",
    "        ('final_labels', orig_results['ws_labels'], ws_labels_pipeline)\n",
    "    ]\n",
    "    \n",
    "    for step_name, orig_data, pipeline_data in check_steps:\n",
    "        if orig_data is not None and pipeline_data is not None:\n",
    "            if isinstance(orig_data, np.ndarray) and isinstance(pipeline_data, np.ndarray):\n",
    "                if not np.array_equal(orig_data, pipeline_data):\n",
    "                    print(f\"ðŸ” DIVERGENCE FOUND at: {step_name}\")\n",
    "                    print(f\"   Original shape: {orig_data.shape}, dtype: {orig_data.dtype}\")\n",
    "                    print(f\"   Pipeline shape: {pipeline_data.shape}, dtype: {pipeline_data.dtype}\")\n",
    "                    if orig_data.dtype == bool:\n",
    "                        print(f\"   Original True pixels: {np.sum(orig_data)}\")\n",
    "                        print(f\"   Pipeline True pixels: {np.sum(pipeline_data)}\")\n",
    "                    else:\n",
    "                        print(f\"   Original unique values: {len(np.unique(orig_data))}\")\n",
    "                        print(f\"   Pipeline unique values: {len(np.unique(pipeline_data))}\")\n",
    "                        print(f\"   Original range: [{orig_data.min()}, {orig_data.max()}]\")\n",
    "                        print(f\"   Pipeline range: [{pipeline_data.min()}, {pipeline_data.max()}]\")\n",
    "                    divergence_found = True\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"âœ“ {step_name}: IDENTICAL\")\n",
    "            else:\n",
    "                print(f\"âš  {step_name}: Cannot compare (type mismatch)\")\n",
    "        else:\n",
    "            print(f\"âš  {step_name}: Missing data\")\n",
    "    \n",
    "    if not divergence_found:\n",
    "        print(\"ðŸ¤” No clear divergence point found - may be floating point precision issue\")\n",
    "\n",
    "else:\n",
    "    print(\"âœ… ALGORITHMS PRODUCE IDENTICAL RESULTS!\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"Original algorithm found: {len(np.unique(orig_results['ws_labels']))} regions\")\n",
    "print(f\"Pipeline algorithm found: {len(np.unique(ws_labels_pipeline))} regions\")\n",
    "print(f\"Test image: {test_red_path.name}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
